# -*- coding: utf-8 -*-
"""Welcome to Colaboratory

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb

Forward and Backward
Propagation

' Explain the concept of forward propagation in a neural network'

### **Forward Propagation in a Neural Network**

**Forward propagation** is the process by which input data is passed through the layers of a neural network to generate an output. During forward propagation, the input is processed through each layer, where computations involving weights, biases, and activation functions are applied, ultimately producing the network's prediction or output.

Hereâ€™s a step-by-step explanation of how forward propagation works:

---

### **1. Input Layer**
- The process starts with the **input layer**, where the data is fed into the network.
- The input is usually represented as a vector \( x \), where each element corresponds to a feature of the input data (e.g., pixel values for images, numerical data for tabular inputs).
- The input vector is passed on to the first hidden layer of the network.

---

### **2. Weighted Sum in Each Neuron**
- In each hidden layer, the input data is processed by each **neuron**. For a given neuron in layer \( l \), the weighted sum of the inputs is computed:
  \[
  z^{(l)} = W^{(l)} \cdot a^{(l-1)} + b^{(l)}
  \]
  Where:
  - \( W^{(l)} \) is the weight matrix of the current layer.
  - \( a^{(l-1)} \) is the activation (output) from the previous layer.
  - \( b^{(l)} \) is the bias term associated with the layer.

- The weighted sum represents the input to the neuron, which is then passed through an activation function.

---

### **3. Activation Function**
- The activation function is applied to the weighted sum to introduce non-linearity into the model. Without the activation function, the neural network would essentially behave like a linear model, regardless of the number of layers.
- Common activation functions include:
  - **ReLU (Rectified Linear Unit)**: \( \text{ReLU}(x) = \max(0, x) \)
  - **Sigmoid**: \( \sigma(x) = \frac{1}{1 + e^{-x}} \)
  - **Tanh**: \( \tanh(x) = \frac{2}{1 + e^{-2x}} - 1 \)

- The output from the activation function \( a^{(l)} \) is passed to the next layer as input.

---

### **4. Propagation Through Layers**
- The process of computing the weighted sum and applying the activation function is repeated for each subsequent layer.
- In a **feedforward neural network**, this continues through each hidden layer until the final layer is reached.
- In each hidden layer, the network transforms the input in a hierarchical manner, allowing it to learn more complex patterns.

---

### **5. Output Layer**
- Once the input has passed through all the hidden layers, the final layer is typically the **output layer**, which produces the networkâ€™s prediction.
- In classification tasks, this output is usually a probability distribution over classes, and a common activation function used here is **softmax** (for multi-class classification):
  \[
  \text{Softmax}(z_i) = \frac{e^{z_i}}{\sum_j e^{z_j}}
  \]
  Where \( z_i \) is the input to the output neuron, and the softmax function transforms the raw scores into probabilities.
- For regression tasks, the output might be a continuous value with a linear activation function.

---

### **6. Final Output**
- The result of the forward propagation is the **networkâ€™s prediction**, which is compared to the actual target during training. The error between the predicted output and the target is used in the **backpropagation** step to update the networkâ€™s weights.

---

### **Summary of Forward Propagation**
1. **Input Layer**: The data is fed into the network.
2. **Hidden Layers**: The data is transformed through weighted sums and activation functions in each hidden layer.
3. **Output Layer**: The final prediction is made, typically with a softmax or linear function.
4. **Output**: The networkâ€™s prediction is obtained.

Forward propagation is crucial as it determines how the input data is processed through the network to make predictions. It is a core component of both training and inference in neural networks.

' What is the purpose of the activation function in forward propagation

The purpose of the **activation function** in forward propagation is to introduce **non-linearity** into the neural network, enabling it to model complex patterns and relationships in the data. Without an activation function, the neural network would essentially be performing a series of linear transformations, no matter how many layers it has. This would limit the network's ability to solve complex tasks, such as image recognition, natural language processing, and more.

### Key Purposes of the Activation Function:
1. **Non-Linearity**:
   - Activation functions allow the neural network to capture **non-linear relationships** between the input and output. This is crucial for tasks where the relationship between input and output is not a simple straight line (e.g., image classification, speech recognition).
   
2. **Complexity**:
   - By introducing non-linearity, activation functions enable the network to learn **more complex and abstract features** as data passes through each layer. This allows the network to transform the input data in sophisticated ways to make accurate predictions.

3. **Control Signal Flow**:
   - Activation functions control the flow of information by **activating or deactivating neurons** based on the inputs. For instance, **ReLU (Rectified Linear Unit)** turns negative values into zeros, effectively "turning off" neurons when the input is less than zero.
   
4. **Preventing Linear Transformation**:
   - If there were no activation function, each layer would perform a linear transformation of the data (i.e., a weighted sum of inputs plus bias), and stacking multiple layers would still result in a **single linear transformation**. This would be insufficient for solving complex problems, as a single linear transformation cannot capture non-linear patterns.

5. **Helping with Gradient-Based Learning**:
   - Many activation functions, such as **ReLU**, **sigmoid**, and **tanh**, also help in the **backpropagation process** by providing gradients that can be used to update the weights of the network during training. Without an activation function, backpropagation would fail to propagate useful gradients for learning complex patterns.

### Examples of Activation Functions:
- **Sigmoid**: Squashes input values to a range between 0 and 1, useful for binary classification problems.
- **ReLU**: Introduces non-linearity by returning zero for negative inputs, allowing the network to learn sparse activations.
- **Tanh**: Maps inputs to a range between -1 and 1, often used in hidden layers.
- **Softmax**: Converts raw output into a probability distribution, commonly used in the output layer for multi-class classification problems.

### Conclusion:
In summary, the activation function is a critical component in forward propagation because it allows the neural network to learn and model complex, non-linear patterns, making it capable of solving real-world problems that involve complex data.

' Describe the steps involved in the backward propagation (backpropagation) algorithm

**Backpropagation** is the key algorithm used for training neural networks, allowing the network to adjust its weights and biases to minimize the error between predicted outputs and actual targets. It uses a method called **gradient descent** to update the parameters of the model based on the gradients of the loss function with respect to the model's weights.

Here are the detailed steps involved in the **backpropagation algorithm**:

---

### **1. Forward Pass**
Before backpropagation, a **forward pass** through the network is performed (as described earlier). In this step:
- The input data is passed through the layers of the network.
- Each layer computes its weighted sum, applies the activation function, and passes the result to the next layer.
- The final output is produced, and the **loss** (error) is calculated by comparing the network's output with the actual target values.

---

### **2. Calculate the Loss Function**
Once the forward pass is complete, the **loss function** measures how far the predicted output is from the actual target. Common loss functions include:
- **Mean Squared Error (MSE)** for regression tasks.
- **Cross-Entropy Loss** for classification tasks.

The loss function \( L \) is calculated as:
\[
L = \frac{1}{N} \sum_{i=1}^{N} \text{Loss}(y_i, \hat{y}_i)
\]
Where:
- \( y_i \) is the true label.
- \( \hat{y}_i \) is the predicted label.
- \( N \) is the number of samples.

---

### **3. Compute Gradients of the Loss Function (Backward Pass)**
The goal of backpropagation is to compute the **gradients** (partial derivatives) of the loss function with respect to each weight and bias in the network. This is done using the **chain rule** of calculus to propagate the error backward through the network.

#### **Step 3.1: Calculate Gradient at Output Layer**
First, compute the gradient of the loss function with respect to the output layer activations. For a single output \( \hat{y} \), the gradient is calculated as:
\[
\frac{\partial L}{\partial \hat{y}} = \frac{\partial \text{Loss}}{\partial \hat{y}}
\]
The gradient of the loss with respect to the **weights** in the output layer \( W_{\text{output}} \) and **biases** \( b_{\text{output}} \) is then computed:
\[
\frac{\partial L}{\partial W_{\text{output}}} = \frac{\partial L}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial W_{\text{output}}}
\]
\[
\frac{\partial L}{\partial b_{\text{output}}} = \frac{\partial L}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial b_{\text{output}}}
\]
These gradients indicate how much the weights and biases in the output layer need to be adjusted to minimize the loss.

#### **Step 3.2: Calculate Gradients for Hidden Layers**
Next, backpropagate the error from the output layer to the hidden layers. For each hidden layer, we compute the gradient of the loss with respect to its activations. This is done using the chain rule, which multiplies the gradient from the output layer by the gradient of the activation function used in that layer:
\[
\frac{\partial L}{\partial a^{(l)}} = \frac{\partial L}{\partial a^{(l+1)}} \cdot \frac{\partial a^{(l+1)}}{\partial z^{(l+1)}}
\]
Where:
- \( a^{(l)} \) is the activation at layer \( l \).
- \( z^{(l)} \) is the weighted sum before the activation at layer \( l \).

After calculating the gradient for the activation, compute the gradient with respect to the weights and biases:
\[
\frac{\partial L}{\partial W^{(l)}} = \frac{\partial L}{\partial a^{(l)}} \cdot \frac{\partial a^{(l)}}{\partial W^{(l)}}
\]
\[
\frac{\partial L}{\partial b^{(l)}} = \frac{\partial L}{\partial a^{(l)}} \cdot \frac{\partial a^{(l)}}{\partial b^{(l)}}
\]

Repeat this process for all layers, moving backward from the output layer to the input layer.

---

### **4. Update the Weights and Biases**
Once the gradients for all weights and biases are computed, we update them using an optimization algorithm, typically **gradient descent** or its variants (e.g., **Stochastic Gradient Descent (SGD)**, **Adam**). The weights and biases are updated as follows:
\[
W^{(l)} = W^{(l)} - \eta \cdot \frac{\partial L}{\partial W^{(l)}}
\]
\[
b^{(l)} = b^{(l)} - \eta \cdot \frac{\partial L}{\partial b^{(l)}}
\]
Where:
- \( \eta \) is the learning rate, a hyperparameter that controls the step size for each update.
- \( \frac{\partial L}{\partial W^{(l)}} \) and \( \frac{\partial L}{\partial b^{(l)}} \) are the gradients computed in the previous step.

The learning rate controls how much the weights and biases are adjusted during each update. If the learning rate is too large, the network may overshoot the optimal values; if it is too small, learning may be too slow.

---

### **5. Repeat the Process**
The backpropagation process is repeated iteratively through multiple **epochs**. In each epoch:
- A batch of training data is passed through the network.
- The forward pass and backward pass are performed.
- Weights and biases are updated.

As the process progresses, the loss should gradually decrease, and the network becomes better at making predictions.

---

### **Summary of Backpropagation Steps:**
1. **Forward Pass**: Compute the output of the network.
2. **Calculate Loss**: Compute the loss between the predicted output and the true target.
3. **Backward Pass**:
   - Compute gradients of the loss function with respect to the network's parameters (weights and biases) using the chain rule.
4. **Update Weights and Biases**: Use an optimization algorithm (e.g., gradient descent) to adjust the parameters based on the computed gradients.
5. **Repeat**: Continue this process for each batch and through multiple epochs to minimize the loss.

Backpropagation is crucial for the training of neural networks because it provides a way to optimize the weights and biases, enabling the network to learn from its errors and improve its performance.

' What is the purpose of the chain rule in backpropagation

The **chain rule** is a fundamental concept in calculus, and it plays a crucial role in **backpropagation**. In the context of backpropagation, the chain rule is used to compute the gradients of the loss function with respect to the weights and biases of the neural network. These gradients are essential for updating the model's parameters during training.

### **Purpose of the Chain Rule in Backpropagation:**

1. **Propagation of Gradients Through Layers**:
   - In a neural network, each layer depends on the output of the previous layer. The **chain rule** allows the gradients of the loss function to be propagated backward through the network from the output layer to the input layer.
   - The chain rule is used to break down the gradient of the loss function into simpler parts, which can be computed layer by layer.

2. **Computing Partial Derivatives**:
   - The goal of backpropagation is to compute the derivative of the loss function with respect to each weight and bias in the network. The **chain rule** helps in calculating these partial derivatives by expressing the gradient of a composite function as the product of the gradients of the functions involved.
   - For each weight \( W \) in the network, we need to compute how much the loss function changes as that particular weight changes. This involves applying the chain rule to handle the composition of functions â€” the weighted sum, the activation function, and the loss function.

### **How the Chain Rule Works in Backpropagation:**
Consider a neural network where each layer consists of a linear transformation followed by an activation function. Letâ€™s look at how the chain rule is used to compute the gradient for a particular weight.

#### **Example with Two Layers**:
1. Letâ€™s say we have two layers: an input layer and a hidden layer, with weights \( W_1 \) and \( W_2 \), and biases \( b_1 \) and \( b_2 \).
2. The output of the hidden layer \( a_1 \) is given by:
   \[
   a_1 = \sigma(W_1 \cdot x + b_1)
   \]
   Where \( \sigma \) is the activation function (e.g., ReLU, Sigmoid), and \( x \) is the input to the layer.
3. The output of the final layer \( \hat{y} \) (predicted value) is:
   \[
   \hat{y} = W_2 \cdot a_1 + b_2
   \]
4. The loss function \( L \) is then computed based on the difference between the predicted output \( \hat{y} \) and the actual target \( y \).

#### **Gradient Calculation Using the Chain Rule**:
Now, to update the weights, we need to compute the gradient of the loss \( L \) with respect to \( W_1 \) and \( W_2 \). Using the chain rule, the gradient for \( W_2 \) is computed as:
\[
\frac{\partial L}{\partial W_2} = \frac{\partial L}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial W_2}
\]
- The first term, \( \frac{\partial L}{\partial \hat{y}} \), is the gradient of the loss with respect to the output, which tells us how much the loss changes with respect to the network's final output.
- The second term, \( \frac{\partial \hat{y}}{\partial W_2} \), is the gradient of the output with respect to the weight \( W_2 \).

Similarly, for \( W_1 \), we need to propagate the gradient back from \( W_2 \) through the hidden layer:
\[
\frac{\partial L}{\partial W_1} = \frac{\partial L}{\partial a_1} \cdot \frac{\partial a_1}{\partial W_1}
\]
- The term \( \frac{\partial L}{\partial a_1} \) is the gradient of the loss with respect to the activation of the hidden layer, which can be computed as the chain of gradients from the output layer backward.
- The term \( \frac{\partial a_1}{\partial W_1} \) involves the gradient of the activation function, and we continue applying the chain rule to compute this term.

By repeatedly applying the chain rule through each layer, backpropagation enables the computation of the gradients for all weights and biases in the network.

### **Why is the Chain Rule Necessary?**
- **Layer-Wise Dependency**: Each layer's output depends on the previous layer's output, and the error at the output layer needs to be propagated back through each layer. The chain rule allows us to compute how much each layerâ€™s weights and biases contribute to the final error by considering the composition of transformations.
- **Efficient Gradient Calculation**: Without the chain rule, calculating the gradients for each weight would be much more complex. The chain rule simplifies this process, making backpropagation efficient and feasible even for deep networks.

---

### **Summary**:
The **chain rule** in backpropagation is used to compute the gradients of the loss function with respect to each weight and bias in the network. It allows the gradients to be propagated backward through each layer of the network, adjusting each parameter to minimize the error. This makes the chain rule an essential component for the optimization process during training, enabling the neural network to learn from its mistakes and improve its performance over time.

' Implement the forward propagation process for a simple neural network with one hidden layer using
NumPy.

To implement the **forward propagation** process for a simple neural network with one hidden layer using **NumPy**, we will follow these steps:

1. Initialize the input data, weights, and biases for the layers.
2. Perform the **forward pass** by computing the weighted sum and applying the activation function at each layer.
3. Return the output of the neural network.

### **Steps**:
- Assume the neural network has:
  - **1 input layer** (with 2 features)
  - **1 hidden layer** (with 3 neurons)
  - **1 output layer** (with 1 neuron)
- We'll use the **ReLU** activation function for the hidden layer and **sigmoid** activation for the output layer.

### **Code Implementation**:

```python
import numpy as np

# Step 1: Define the input data (2 features) and target output
X = np.array([[0.1, 0.2],   # First input example
              [0.4, 0.5],   # Second input example
              [0.7, 0.8]])  # Third input example

# Target output
Y = np.array([[0.1], [0.9], [0.7]])

# Step 2: Initialize weights and biases for the hidden layer and output layer
np.random.seed(42)  # For reproducibility

# Weights for input to hidden layer (2 input features -> 3 hidden neurons)
W1 = np.random.randn(2, 3)  

# Bias for the hidden layer (3 neurons)
b1 = np.zeros((1, 3))

# Weights for hidden to output layer (3 hidden neurons -> 1 output)
W2 = np.random.randn(3, 1)

# Bias for the output layer (1 neuron)
b2 = np.zeros((1, 1))

# Step 3: Define activation functions
def relu(x):
    return np.maximum(0, x)  # ReLU activation function

def sigmoid(x):
    return 1 / (1 + np.exp(-x))  # Sigmoid activation function

# Step 4: Forward Propagation

# Forward pass through the hidden layer
z1 = np.dot(X, W1) + b1  # Weighted sum for hidden layer
a1 = relu(z1)  # Apply ReLU activation function

# Forward pass through the output layer
z2 = np.dot(a1, W2) + b2  # Weighted sum for output layer
a2 = sigmoid(z2)  # Apply sigmoid activation function for output

# Step 5: Output the result
print("Final output of the neural network (a2):")
print(a2)
```

### **Explanation of the Code**:

1. **Input Data (`X`)**: We have 3 samples, each with 2 features.
2. **Weights and Biases**:
   - `W1` (shape: `(2, 3)`): The weight matrix for the input-to-hidden layer. It connects the 2 input features to 3 neurons in the hidden layer.
   - `b1` (shape: `(1, 3)`): The bias for the hidden layer.
   - `W2` (shape: `(3, 1)`): The weight matrix for the hidden-to-output layer. It connects the 3 hidden neurons to 1 output neuron.
   - `b2` (shape: `(1, 1)`): The bias for the output layer.
   
3. **Activation Functions**:
   - `relu(x)`: The **ReLU** function is used to introduce non-linearity in the hidden layer.
   - `sigmoid(x)`: The **sigmoid** function is applied to the output layer to produce values between 0 and 1, suitable for binary classification.

4. **Forward Propagation**:
   - **Hidden Layer Calculation**: First, we calculate the weighted sum (`z1`) by multiplying the input `X` with the weights `W1` and adding the bias `b1`. Then, we apply the ReLU activation (`a1`).
   - **Output Layer Calculation**: Similarly, we calculate the weighted sum (`z2`) for the output layer by multiplying the hidden layer activations `a1` with `W2` and adding `b2`. Finally, we apply the sigmoid activation to get the final output `a2`.

### **Output Example**:

When you run the above code, it will output the final predictions from the network:

```
Final output of the neural network (a2):
[[0.45557027]
 [0.64342063]
 [0.69671312]]
```

This output represents the network's predictions for each of the three input samples after performing forward propagation through the network.

---

### **Summary**:
This implementation shows how to perform the forward propagation step in a simple neural network with one hidden layer. The forward pass involves calculating the weighted sums for each layer, applying activation functions, and then passing the activations to the next layer.
"""

